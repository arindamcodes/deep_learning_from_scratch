{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(12345)\n",
    "random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'd MMM YYY', \n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n",
    "\n",
    "# change this if you want it to work with another language\n",
    "LOCALES = ['en_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_date():\n",
    "    \"\"\"\n",
    "        Loads some fake dates \n",
    "        :returns: tuple containing human readable string, machine readable string, and date object\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US') # locale=random.choice(LOCALES))\n",
    "        human_readable = human_readable.lower()\n",
    "        human_readable = human_readable.replace(',','')\n",
    "        machine_readable = dt.isoformat()\n",
    "        \n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable, dt\n",
    "\n",
    "def load_dataset(m):\n",
    "    \"\"\"\n",
    "        Loads a dataset with m examples and vocabularies\n",
    "        :m: the number of examples to generate\n",
    "    \"\"\"\n",
    "    \n",
    "    human_vocab = set()\n",
    "    machine_vocab = set()\n",
    "    dataset = []\n",
    "    \n",
    "\n",
    "    for i in tqdm(range(m)):\n",
    "        h, m, _ = load_date()\n",
    "        if h is not None:\n",
    "            dataset.append((h, m))\n",
    "            human_vocab.update(tuple(h))\n",
    "            machine_vocab.update(tuple(m))\n",
    "    \n",
    "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], \n",
    "                     list(range(len(human_vocab) + 2))))\n",
    "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
    "    machine = {v:k for k,v in inv_machine.items()}\n",
    "    return dataset, human, machine, inv_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 43742.25it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dates, machine_dates = zip(*dataset)\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "Tx = 30\n",
    "Ty = 10\n",
    "\n",
    "for string in human_dates:\n",
    "    rep = list(map(lambda x: human_vocab.get(x, '<unk>'), string))\n",
    "    if len(string) < Tx:\n",
    "        rep += [human_vocab['<pad>']] * (Tx - len(string))\n",
    "    X.append(rep)\n",
    "    \n",
    "\n",
    "for date in machine_dates:\n",
    "    rep = list(map(lambda x: machine_vocab.get(x), date))\n",
    "    Y.append(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.long)\n",
    "Y = torch.tensor(Y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationData(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = TranslationData(X, Y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.GRU = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        o, h = self.GRU(x)\n",
    "        return o, h  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tensor = torch.zeros(32, 10, dtype=torch.long)\n",
    "e = Encoder(30, 64, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 64])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.embedding(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 40])\n",
      "torch.Size([1, 32, 40])\n"
     ]
    }
   ],
   "source": [
    "o, h = e.forward(x)\n",
    "print(o.shape)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tmp = h.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 40])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_h = h_tmp.view(32, 1, 40).repeat(1, 10, 1)\n",
    "repeat_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 80])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_vector = torch.cat([o, repeat_h], dim=2)\n",
    "concat_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_hidden = nn.Linear(80, 40)\n",
    "att_final = nn.Linear(40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = att_hidden(concat_vector)\n",
    "f2 = att_final(f1)\n",
    "f2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(2 * embedding_dim, embedding_dim)\n",
    "        self.out = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_output):\n",
    "        # decoder hidden (1, batch_size, hidden_dim)\n",
    "        # encoder output (batch_size, Tx, hidden_dim)\n",
    "        Tx = encoder_output.shape[1]\n",
    "        decoder_hidden = decoder_hidden.permute(1, 0, 2)\n",
    "        decoder_hidden_repeat = decoder_hidden.repeat(1, Tx, 1)\n",
    "        concat = torch.concat([encoder_output, decoder_hidden_repeat], dim=2)\n",
    "        att_hidden = self.fc(concat) #(batch_size, TX, hidden_dim)\n",
    "        raw_att = self.out(att_hidden) #(batch_size, Tx, 1)\n",
    "        raw_att = raw_att.squeeze(2) # (batch_size, Tx)\n",
    "        att = torch.softmax(raw_att, dim=1) # (batch_size, Tx)\n",
    "        att = att.unsqueeze(1) #(batch_size, 1, Tx)\n",
    "        context = torch.matmul(att, encoder_output) #(batch_size, 1, hidden_dim)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.sum(f2 * o, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 40])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_hidden_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.GRU = nn.GRU(embedding_dim + encoder_hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, context, hidden):\n",
    "        x = self.embedding(x)\n",
    "        context_input = torch.concat([context, x], axis=2)\n",
    "        o, h = self.GRU(context_input, hidden)\n",
    "        o = self.out(o)\n",
    "        return o, h   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Decoder(30, 34, 40, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.zeros(32, 1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_d = torch.randn((1, 32, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "do, dh = d(x1, c, h_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 30]), torch.Size([1, 32, 50]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.shape, dh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionNMT(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, attention):\n",
    "        super(AttentionNMT, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.attention = attention\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        Ty = trg.shape[1] \n",
    "        decoder_vocab_size = self.decoder.vocab_size\n",
    "        encoder_output, encoder_hidden = self.encoder(src)\n",
    "        decoder_hidden_dim = self.decoder.hidden_dim\n",
    "        batch_size = src.shape[0]\n",
    "        decoder_hidden = encoder_hidden\n",
    "        x = trg[:, 0:1]\n",
    "        outputs = torch.zeros((batch_size, Ty, decoder_vocab_size))\n",
    "        for ty in range(1, Ty):\n",
    "            context = self.attention(decoder_hidden, encoder_output)\n",
    "            output, decoder_hidden = self.decoder(x, context, decoder_hidden)\n",
    "            outputs[:, ty:ty+1, :] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(2)\n",
    "            x = trg[:, ty:ty+1] if teacher_force else top1\n",
    "        return outputs    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(30, 12, 18)\n",
    "attention = Attention(18)\n",
    "decoder = Decoder(30, 12, 18, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "atnmt = AttentionNMT(encoder, decoder, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.zeros((8, 20), dtype=torch.long)\n",
    "trg = torch.zeros((8, 20), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ty = trg.shape[1]\n",
    "decoder_vocab_size = atnmt.decoder.vocab_size\n",
    "encoder_output, encoder_hidden = atnmt.encoder(src)\n",
    "batch_size = src.shape[0]\n",
    "decoder_hidden = encoder_hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_debug = trg[:, 0:1]\n",
    "x_debug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.zeros((batch_size, Ty, decoder_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 18]), torch.Size([8, 20, 18]))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_hidden.shape, encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = atnmt.attention(decoder_hidden, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 18])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden = torch.randn((1, 8, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, decoder_hidden = atnmt.decoder(x_debug, context, decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 20, 30])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atnmt(src, trg).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vocab_size = len(human_vocab)\n",
    "machine_vocab_size = len(machine_vocab)\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(human_vocab_size, embedding_dim, hidden_dim)\n",
    "attention = Attention(hidden_dim)\n",
    "decoder = Decoder(machine_vocab_size, embedding_dim, hidden_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionNMT(encoder, decoder, attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.24060807046227561\n",
      "Epoch [2/100], Loss: 0.24053240641237447\n",
      "Epoch [3/100], Loss: 0.2495299641031046\n",
      "Epoch [4/100], Loss: 0.2412043185279773\n",
      "Epoch [5/100], Loss: 0.24042587786817704\n",
      "Epoch [6/100], Loss: 0.2427664488649216\n",
      "Epoch [7/100], Loss: 0.2435496563728625\n",
      "Epoch [8/100], Loss: 0.24036414659442232\n",
      "Epoch [9/100], Loss: 0.240243951923931\n",
      "Epoch [10/100], Loss: 0.24010902743179577\n",
      "Epoch [11/100], Loss: 0.2400962632780258\n",
      "Epoch [12/100], Loss: 0.24007657684457187\n",
      "Epoch [13/100], Loss: 0.24043203599917623\n",
      "Epoch [14/100], Loss: 0.24594179700357846\n",
      "Epoch [15/100], Loss: 0.24088659430273807\n",
      "Epoch [16/100], Loss: 0.24008390502617383\n",
      "Epoch [17/100], Loss: 0.2400757955571714\n",
      "Epoch [18/100], Loss: 0.23996134811696915\n",
      "Epoch [19/100], Loss: 0.23995831365973805\n",
      "Epoch [20/100], Loss: 0.24022830241975693\n",
      "Epoch [21/100], Loss: 0.2474093888514339\n",
      "Epoch [22/100], Loss: 0.2401900974611124\n",
      "Epoch [23/100], Loss: 0.24003631871538803\n",
      "Epoch [24/100], Loss: 0.24005432764943035\n",
      "Epoch [25/100], Loss: 0.24010603972517264\n",
      "Epoch [26/100], Loss: 0.23997414421540098\n",
      "Epoch [27/100], Loss: 0.23994350776123924\n",
      "Epoch [28/100], Loss: 0.23990384582132576\n",
      "Epoch [29/100], Loss: 0.23998531280234217\n",
      "Epoch [30/100], Loss: 0.2398827983358036\n",
      "Epoch [31/100], Loss: 0.2398711342971546\n",
      "Epoch [32/100], Loss: 0.23988318338561743\n",
      "Epoch [33/100], Loss: 0.24709876533895256\n",
      "Epoch [34/100], Loss: 0.2406470642779201\n",
      "Epoch [35/100], Loss: 0.2400860367015528\n",
      "Epoch [36/100], Loss: 0.24014405730052496\n",
      "Epoch [37/100], Loss: 0.23993335692836834\n",
      "Epoch [38/100], Loss: 0.2398822044316953\n",
      "Epoch [39/100], Loss: 0.23986946108242194\n",
      "Epoch [40/100], Loss: 0.23987263836228429\n",
      "Epoch [41/100], Loss: 0.24009373788826002\n",
      "Epoch [42/100], Loss: 0.24423332002977974\n",
      "Epoch [43/100], Loss: 0.2403467538924263\n",
      "Epoch [44/100], Loss: 0.24000817861039037\n",
      "Epoch [45/100], Loss: 0.2400854489864252\n",
      "Epoch [46/100], Loss: 0.23989003482527627\n",
      "Epoch [47/100], Loss: 0.23986821300305497\n",
      "Epoch [48/100], Loss: 0.2398691037878061\n",
      "Epoch [49/100], Loss: 0.23984536866600903\n",
      "Epoch [50/100], Loss: 0.23984292882699937\n",
      "Epoch [51/100], Loss: 0.239835973412465\n",
      "Epoch [52/100], Loss: 0.2398313570041626\n",
      "Epoch [53/100], Loss: 0.23983882696102984\n",
      "Epoch [54/100], Loss: 0.246611363257463\n",
      "Epoch [55/100], Loss: 0.24001674692089947\n",
      "Epoch [56/100], Loss: 0.23989248542359082\n",
      "Epoch [57/100], Loss: 0.23987212729530213\n",
      "Epoch [58/100], Loss: 0.2398601744216852\n",
      "Epoch [59/100], Loss: 0.23985238020983748\n",
      "Epoch [60/100], Loss: 0.23984534191056944\n",
      "Epoch [61/100], Loss: 0.23984301285431409\n",
      "Epoch [62/100], Loss: 0.239836678575403\n",
      "Epoch [63/100], Loss: 0.23983173615064102\n",
      "Epoch [64/100], Loss: 0.23983219289741578\n",
      "Epoch [65/100], Loss: 0.24501779903999912\n",
      "Epoch [66/100], Loss: 0.24047333554337963\n",
      "Epoch [67/100], Loss: 0.23992809543784815\n",
      "Epoch [68/100], Loss: 0.2398806211476128\n",
      "Epoch [69/100], Loss: 0.23986366257880823\n",
      "Epoch [70/100], Loss: 0.23985407727594954\n",
      "Epoch [71/100], Loss: 0.23984390416274817\n",
      "Epoch [72/100], Loss: 0.23983882867490142\n",
      "Epoch [73/100], Loss: 0.23983488005761522\n",
      "Epoch [74/100], Loss: 0.23983016629188586\n",
      "Epoch [75/100], Loss: 0.23982652388632106\n",
      "Epoch [76/100], Loss: 0.23982512265348588\n",
      "Epoch [77/100], Loss: 0.23998330714413152\n",
      "Epoch [78/100], Loss: 0.24474885926459924\n",
      "Epoch [79/100], Loss: 0.24024701223205835\n",
      "Epoch [80/100], Loss: 0.23993853748606417\n",
      "Epoch [81/100], Loss: 0.23985740404349928\n",
      "Epoch [82/100], Loss: 0.23984435667245152\n",
      "Epoch [83/100], Loss: 0.23983613822978145\n",
      "Epoch [84/100], Loss: 0.23983131682339567\n",
      "Epoch [85/100], Loss: 0.2398274750850452\n",
      "Epoch [86/100], Loss: 0.23982448471239962\n",
      "Epoch [87/100], Loss: 0.23982201926053143\n",
      "Epoch [88/100], Loss: 0.23981918704014615\n",
      "Epoch [89/100], Loss: 0.23981729264076526\n",
      "Epoch [90/100], Loss: 0.24447907474094305\n",
      "Epoch [91/100], Loss: 0.2402896848730386\n",
      "Epoch [92/100], Loss: 0.2399836698183998\n",
      "Epoch [93/100], Loss: 0.24065061065906915\n",
      "Epoch [94/100], Loss: 0.2401456690063111\n",
      "Epoch [95/100], Loss: 0.23991315428631754\n",
      "Epoch [96/100], Loss: 0.23985006933966382\n",
      "Epoch [97/100], Loss: 0.2398389208431061\n",
      "Epoch [98/100], Loss: 0.23983423364238618\n",
      "Epoch [99/100], Loss: 0.23987518222377704\n",
      "Epoch [100/100], Loss: 0.23983172124947982\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for X, Y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X, Y)\n",
    "        #print(outputs.shape)\n",
    "        #print(Y.shape)\n",
    "        loss = criterion(outputs.view(-1, machine_vocab_size), Y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss/len(dataloader)}')   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_date(human_date):\n",
    "    rep = list(map(lambda x: human_vocab.get(x, '<unk>'), human_date))\n",
    "    if len(human_date) < Tx:\n",
    "        rep += [human_vocab['<pad>']] * (Tx - len(human_date))\n",
    "    \n",
    "    X = torch.tensor(rep, dtype=torch.long)\n",
    "    X = X.view(1, X.shape[0])\n",
    "    \n",
    "    date_start_idx = machine_vocab.get(\"2\")\n",
    "    decoder_input = torch.tensor([date_start_idx]).view(1, 1)\n",
    "    with torch.no_grad():\n",
    "        encoder_output, encoder_hidden = encoder(X)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        output = [date_start_idx]\n",
    "        for ty in range(1, Ty):\n",
    "            context = model.attention(decoder_hidden, encoder_output)\n",
    "            decoder_output, decoder_hidden = model.decoder(decoder_input, context, decoder_hidden)\n",
    "            #print(decoder_output.shape)\n",
    "            top_token_idx = torch.argmax(decoder_output, dim=2)\n",
    "            output.append(top_token_idx.item())\n",
    "            decoder_input = top_token_idx\n",
    "    \n",
    "    output = output\n",
    "    ds = list(map(lambda x: inv_machine_vocab.get(x), output))\n",
    "    ds = \"\".join(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2001-06-04'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_date(\"4th of july 2001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"nmt_attention.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
